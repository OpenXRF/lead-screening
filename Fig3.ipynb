{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+GEHa68BpEVdi0amfkLu4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OpenXRF/lead-screening/blob/main/Fig3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![OpenXRF_logo_red.svg](data:image/svg+xml;base64,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)"
      ],
      "metadata": {
        "id": "-ZyG2nM1Rz1S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Towards low-cost lead screening with transmission XRF\n",
        "---\n",
        "\n",
        "\n",
        "[Citation]\n",
        "\n",
        "\n",
        "*   Project website: [openxrf.org](https://openxrf.org/)\n",
        "*   Project GitHub: [github.com/OpenXRF/lead-screening](https://github.com/OpenXRF/lead-screening/)\n"
      ],
      "metadata": {
        "id": "l_ElApC_R6iA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Figure 3: Showing LOD threasholds\n",
        "\n",
        "* Callculating SNR for 10, 50, 100, 200, 500, 1000 ppm Pb in soil\n",
        "* 2h max exposure for all ppm values\n",
        "* Data is provided in Google Drive\n",
        "\n",
        "-> Script computes the visualized data and displays the plot itself in the last cell..."
      ],
      "metadata": {
        "id": "RhLBvKHMR5v1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install packages { display-mode: \"form\" }\n",
        "# @markdown Python packages for data processing and visualization\n",
        "\n",
        "!pip install -q gdown pandas numpy matplotlib plotly\n",
        "import gdown\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.optimize import curve_fit\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "from time import time\n",
        "\n",
        "print(\"All packages installed successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHs7tF5WStOi",
        "outputId": "810eab1b-a0e0-4f34-915c-e5f88013bb95"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All packages installed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1) Load simulated data\n",
        "## @markdown Loading the data from Drive and add the energy resolution and the radius\n",
        "\n",
        "#Drive IDs\n",
        "\n",
        "start_time = time()\n",
        "\n",
        "ID_10_0 = \"14Ie8XVcdB__RBZzvPiEQ-Gi4AdX4tKEh\"\n",
        "ID_10_1 = \"1tX7mb81rHj4HCiuefO3RGTJEr1F6mmGO\"\n",
        "ID_10_2 = \"1a4p1p1BTF6RFzNr_ZFgUtbZ1kg3OvYjj\"\n",
        "ID_10_3 = \"1f4IsH-72QQizuZdoI7d_KFTXM-G_c36i\"\n",
        "ID_10_4 = \"1DhfeCh-P56MPfeO9bh830EKZe1WSMBkp\"\n",
        "ID_10_5 = \"157_sJfWBRId8TvBQqgqF94O02ktwHP2U\"\n",
        "ID_10_6 = \"1ODVjzullAOqDeHKRgSz4YJTtmUI4h45R\"\n",
        "\n",
        "ID_50_0 = \"1SBXNvIt9RtEs-WJExY2Ph9Ptmc_o-qME\"\n",
        "ID_50_1 = \"1IH0Of7CfK9cnvTWUKhEqay8iiQt_vUEC\"\n",
        "ID_50_2 = \"1fiZbNpS0jzS651iC9Zg6OlKgGYwdmWLI\"\n",
        "ID_50_3 = \"1_yIR55ajSCSKD_M2JDX3Q2xFmK5yEzrW\"\n",
        "ID_50_4 = \"1YF0YcTshUX6VMoqr08xOyJt1ChfWvQyG\"\n",
        "ID_50_5 = \"198W2-VjYlNQQR0fWnGpJ_xlaef0uXkxi\"\n",
        "ID_50_6 = \"1VBExZ7AU7xc7vNuGYvd-Rt-jk3qJZa9t\"\n",
        "\n",
        "ID_100_0 = \"1CMosVezrnpJSAyM4EumSCim_BHKj2nXd\"\n",
        "ID_100_1 = \"1SzqKSACYTQBodMxHZdoVfs3oFI9Ww_gB\"\n",
        "ID_100_2 = \"1ORShpAKY_Sgzz3odSIoT4g-piIm3neAL\"\n",
        "ID_100_3 = \"1Ywki8jrTJZ6ojiEg-qSmXh05KAmkXjxm\"\n",
        "ID_100_4 = \"1Ab1fUVQwk8dQxHpKM-VNDfRWuDX3oD7C\"\n",
        "ID_100_5 = \"1zHNjkPcghWdVFPfQ1pZ9Wm8Woe0zm-hj\"\n",
        "ID_100_6 = \"1-8XsKdq79xtAWtX04VUQeRUsKfSZ0ikO\"\n",
        "\n",
        "ID_200_0 = \"1f72MKreFJc6lPkmFWiilcRA1dV7z7wjV\"\n",
        "ID_200_1 = \"1UNKIt370FKnp-D_E_RNK9EHyu6gquBEj\"\n",
        "ID_200_2 = \"1nmDeGP6eHXl_mj1oARZbwpveX5sJlwzm\"\n",
        "ID_200_3 = \"1BH380btO5mKP5JHFmYV0mptTBv-O-QEW\"\n",
        "ID_200_4 = \"1ksh3hYTpq69jU4srbkDh3CsBbGtCXQqQ\"\n",
        "ID_200_5 = \"1M9792wHtc6CpiHe7bySofGxzw4OZhGaq\"\n",
        "ID_200_6 = \"1qvpdKHlsa5bEp_9kHACTKrj-4o3_j1IR\"\n",
        "\n",
        "ID_500_0 = \"1vxyeftCuV7rJKvbal0DRiwX52ZXr1wRA\"\n",
        "ID_500_1 = \"1T1IXqNwGvAjBVdHp8vl2mXuGYpybms94\"\n",
        "ID_500_2 = \"14pIhwrFE1DHyRlFYTDBWWbhUnk7TXxGq\"\n",
        "ID_500_3 = \"1qZot0yXnbKP9w80WhSAo_fyRW-K0_uMy\"\n",
        "ID_500_4 = \"19VL-6BgK5juD3H91kDNIjs-usjKNJL5X\"\n",
        "ID_500_5 = \"14bCJvYhENSK3vnTUezHZFVjIDL1CPms7\"\n",
        "ID_500_6 = \"1tTudvasUyfJpLEnuLGQ_uO53KPD87xvf\"\n",
        "\n",
        "ID_1000_0 = \"1FEvvAw3xApOI2uJBGiaGiaP2we5aY0dz\"\n",
        "ID_1000_1 = \"1lP-pLKILJwQliF0EokGrCyxvTNg8QJyi\"\n",
        "ID_1000_2 = \"1C_yBwnMvP44Jnn2CaUEn7Y6qRPO5PZIm\"\n",
        "ID_1000_3 = \"1b3JrEi0BiI2hIv-thX7bZyx5bv8UW0Pe\"\n",
        "ID_1000_4 = \"1oRSHcxBa8Dgz-fJGkorPxz2EEj2eNwVV\"\n",
        "ID_1000_5 = \"1P6SDkaKuPWn60Yglu_dRhzek9aO0UtET\"\n",
        "ID_1000_6 = \"1qo5_wEz-Q_VYIn6EvRpAVyx62lAzjgcS\"\n",
        "\n",
        "\n",
        "\n",
        "def read_dataset(base_conc):\n",
        "    \"\"\"\n",
        "    Reads the 7 data csv files for one ppm concentration\n",
        "    output: {'S0': df, ..., 'S6': df}\n",
        "    \"\"\"\n",
        "    ds = {}\n",
        "    for source_number in range(7):\n",
        "        var_name = f\"ID_{base_conc}_{source_number}\"\n",
        "        try:\n",
        "            file_id = globals()[var_name]\n",
        "        except KeyError:\n",
        "            raise KeyError(f\"Variable '{var_name}' not defined.\")\n",
        "        url = f\"https://drive.google.com/uc?export=download&id={file_id}\"\n",
        "        gdown.download(url = url,\n",
        "               output=f'data_{base_conc}_{source_number}.csv',\n",
        "               quiet=True, fuzzy=True, use_cookies=False)\n",
        "        df = pd.read_csv(f'data_{base_conc}_{source_number}.csv')\n",
        "        ds[f\"S{source_number}\"] = df\n",
        "    return ds\n",
        "\n",
        "def add_energy_resolution_and_radius(ds_dict, FWHM_keV, detector_radius_mm, rng):\n",
        "    \"\"\"\n",
        "    Adds 'E' (Resolution) and 'r_hit'.\n",
        "    \"\"\"\n",
        "    for k, df in ds_dict.items():\n",
        "        E_keV = df[\"Energy_MeV_\"] * 1000.0\n",
        "        sigma = FWHM_keV / 2.355\n",
        "        E_keV_res = E_keV + rng.normal(0, sigma, size=len(df))\n",
        "        df[\"E\"] = E_keV_res\n",
        "\n",
        "        r_hit = np.sqrt(df[\"x_mm_\"]**2 + df[\"y_mm_\"]**2)\n",
        "        df[\"r_hit\"] = r_hit\n",
        "\n",
        "    return ds_dict\n",
        "\n",
        "rng = np.random.default_rng(0)\n",
        "\n",
        "print(\"Reading simulated data...\")\n",
        "\n",
        "c_vals = np.array([10, 50, 100, 200, 500, 1000])  # ppm\n",
        "\n",
        "data10ppm = read_dataset(10)\n",
        "print('Done 10ppm')\n",
        "data50ppm = read_dataset(50)\n",
        "print('Done 50ppm')\n",
        "data100ppm = read_dataset(100)\n",
        "print('Done 100ppm')\n",
        "data200ppm = read_dataset(200)\n",
        "print('Done 200ppm')\n",
        "data500ppm = read_dataset(500)\n",
        "print('Done 500ppm')\n",
        "data1000ppm = read_dataset(1000)\n",
        "print('Done 1000ppm')\n",
        "\n",
        "FWHM_keV = 0.15\n",
        "print(f\"Adding realistic energy resolution: {FWHM_keV:.2f} keV...\")\n",
        "\n",
        "detector_area = 50.0  # mm^2\n",
        "detector_radius = np.sqrt(detector_area / np.pi)  # mm\n",
        "\n",
        "datasets = [\n",
        "    data10ppm,\n",
        "    data50ppm,\n",
        "    data100ppm,\n",
        "    data200ppm,\n",
        "    data500ppm,\n",
        "    data1000ppm,\n",
        "]\n",
        "\n",
        "for i in range(len(datasets)):\n",
        "    datasets[i] = add_energy_resolution_and_radius(\n",
        "        datasets[i],\n",
        "        FWHM_keV=FWHM_keV,\n",
        "        detector_radius_mm=detector_radius,\n",
        "        rng=rng\n",
        "    )\n",
        "\n",
        "(data10ppm,\n",
        "  data50ppm,\n",
        "  data100ppm,\n",
        "  data200ppm,\n",
        "  data500ppm,\n",
        "  data1000ppm) = datasets\n",
        "\n",
        "print(f\"Data loaded successfully (took {time() - start_time:.1f} s)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "kEwqO9KUXE52",
        "outputId": "c8e4cc8a-f30c-47f5-e05c-00e5e1349712"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading simulated data...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileURLRetrievalError",
          "evalue": "Failed to retrieve file url:\n\n\tCannot retrieve the public link of the file. You may need to change\n\tthe permission to 'Anyone with the link', or have had many accesses.\n\tCheck FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.\n\nYou may still be able to access the file from the browser:\n\n\thttps://drive.google.com/uc?id=14Ie8XVcdB__RBZzvPiEQ-Gi4AdX4tKEh\n\nbut Gdown can't. Please check connections and permissions.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gdown/download.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume, format, user_agent, log_messages)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_url_from_gdrive_confirmation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileURLRetrievalError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gdown/download.py\u001b[0m in \u001b[0;36mget_url_from_gdrive_confirmation\u001b[0;34m(contents)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         raise FileURLRetrievalError(\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0;34m\"Cannot retrieve the public link of the file. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m: Cannot retrieve the public link of the file. You may need to change the permission to 'Anyone with the link', or have had many accesses. Check FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3320056217.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0mc_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# ppm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m \u001b[0mdata10ppm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done 10ppm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0mdata50ppm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3320056217.py\u001b[0m in \u001b[0;36mread_dataset\u001b[0;34m(base_conc)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Variable '{var_name}' not defined.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"https://drive.google.com/uc?export=download&id={file_id}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         gdown.download(url = url,\n\u001b[0m\u001b[1;32m     72\u001b[0m                \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'data_{base_conc}_{source_number}.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                quiet=True, fuzzy=True, use_cookies=False)\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gdown/download.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume, format, user_agent, log_messages)\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0murl_origin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             )\n\u001b[0;32m--> 278\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileURLRetrievalError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0mfilename_from_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m: Failed to retrieve file url:\n\n\tCannot retrieve the public link of the file. You may need to change\n\tthe permission to 'Anyone with the link', or have had many accesses.\n\tCheck FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.\n\nYou may still be able to access the file from the browser:\n\n\thttps://drive.google.com/uc?id=14Ie8XVcdB__RBZzvPiEQ-Gi4AdX4tKEh\n\nbut Gdown can't. Please check connections and permissions."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data10ppm = read_dataset(10)\n",
        "print('Done 10ppm')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "5-N66e9vqaDK",
        "outputId": "0f9c746b-cdad-459b-c2fb-9add6622576c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileURLRetrievalError",
          "evalue": "Failed to retrieve file url:\n\n\tCannot retrieve the public link of the file. You may need to change\n\tthe permission to 'Anyone with the link', or have had many accesses.\n\tCheck FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.\n\nYou may still be able to access the file from the browser:\n\n\thttps://drive.google.com/uc?id=14Ie8XVcdB__RBZzvPiEQ-Gi4AdX4tKEh\n\nbut Gdown can't. Please check connections and permissions.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gdown/download.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume, format, user_agent, log_messages)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_url_from_gdrive_confirmation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileURLRetrievalError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gdown/download.py\u001b[0m in \u001b[0;36mget_url_from_gdrive_confirmation\u001b[0;34m(contents)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         raise FileURLRetrievalError(\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0;34m\"Cannot retrieve the public link of the file. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m: Cannot retrieve the public link of the file. You may need to change the permission to 'Anyone with the link', or have had many accesses. Check FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1783544846.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata10ppm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done 10ppm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3320056217.py\u001b[0m in \u001b[0;36mread_dataset\u001b[0;34m(base_conc)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Variable '{var_name}' not defined.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"https://drive.google.com/uc?export=download&id={file_id}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         gdown.download(url = url,\n\u001b[0m\u001b[1;32m     72\u001b[0m                \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'data_{base_conc}_{source_number}.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                quiet=True, fuzzy=True, use_cookies=False)\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gdown/download.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume, format, user_agent, log_messages)\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0murl_origin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             )\n\u001b[0;32m--> 278\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileURLRetrievalError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0mfilename_from_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m: Failed to retrieve file url:\n\n\tCannot retrieve the public link of the file. You may need to change\n\tthe permission to 'Anyone with the link', or have had many accesses.\n\tCheck FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.\n\nYou may still be able to access the file from the browser:\n\n\thttps://drive.google.com/uc?id=14Ie8XVcdB__RBZzvPiEQ-Gi4AdX4tKEh\n\nbut Gdown can't. Please check connections and permissions."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RxncPYF4QwWh"
      },
      "outputs": [],
      "source": [
        "#@title 2) Analyse experimental parameters and visualize results { display-mode: \"form\" }\n",
        "\n",
        "def snr_model(t, A):\n",
        "    # SNR = A * sqrt(t)\n",
        "    return A * np.sqrt(t)\n",
        "\n",
        "\n",
        "def lod_model(t, A1, A2):\n",
        "    # c_LOD(t) = (A1 + sqrt(A1^2 + A2*t)) / t\n",
        "    return (A1 + np.sqrt(A1**2 + A2 * t)) / t\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Peak-Parameter\n",
        "# ------------------------------------------------------------\n",
        "peak = {\n",
        "    \"alpha\": {\"E\": 10.55},  # keV\n",
        "    \"beta\": {\"E\": 12.65},\n",
        "    \"window\": FWHM_keV\n",
        "}\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Time values\n",
        "# ------------------------------------------------------------\n",
        "fluence = 995 * np.pi * 2 * (1 - np.cos(np.pi / 4))  # ph/s per source\n",
        "step_size_min = 5  # min\n",
        "max_event = 180 * 60 * fluence\n",
        "step_size = step_size_min * 60 * fluence\n",
        "num_steps = int(np.floor(max_event / step_size))\n",
        "time_values = np.arange(1, num_steps + 1) * step_size_min  # in min\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Histogramm-Setup\n",
        "# ------------------------------------------------------------\n",
        "T = np.array([10, 30, 60])  # min\n",
        "T_steps = (T / step_size_min).astype(int)\n",
        "\n",
        "binwidth = 0.03  # keV\n",
        "E = np.arange(0, 75 + binwidth, binwidth)\n",
        "\n",
        "\n",
        "# Container for SNR-Data\n",
        "SNR = [dict() for _ in range(len(c_vals))]\n",
        "saved_histograms = {}\n",
        "\n",
        "print(\"\\n=== Calculating SNR over time ===\")\n",
        "\n",
        "for conc_idx, conc in enumerate(c_vals):\n",
        "    print(f\"Processing {conc} ppm...\")\n",
        "\n",
        "    signal_over_time = np.zeros(num_steps)\n",
        "    background_over_time = np.zeros(num_steps)\n",
        "    signal_over_time_S0 = np.zeros(num_steps)\n",
        "    background_over_time_S0 = np.zeros(num_steps)\n",
        "\n",
        "    SNR[conc_idx][\"alpha_individual\"] = np.zeros((7, num_steps))\n",
        "    SNR[conc_idx][\"beta_individual\"] = np.zeros((7, num_steps))\n",
        "    SNR[conc_idx][\"total_individual\"] = np.zeros((7, num_steps))\n",
        "\n",
        "    for step in range(1, num_steps + 1):\n",
        "        end_event = step * step_size\n",
        "        current_time = step * step_size_min\n",
        "        print(f\" - {current_time} min...\")\n",
        "\n",
        "        total_alpha_secondary = 0\n",
        "        total_alpha_primary = 0\n",
        "        total_beta_secondary = 0\n",
        "        total_beta_primary = 0\n",
        "\n",
        "        is_save_point = step in T_steps\n",
        "        if is_save_point:\n",
        "            combined_primary_hist = np.zeros_like(E)\n",
        "            combined_secondary_hist = np.zeros_like(E)\n",
        "\n",
        "        # all 7 Sources\n",
        "        for s in range(7):\n",
        "            field = f\"S{s}\"\n",
        "            data = datasets[conc_idx][field]\n",
        "\n",
        "            mask = (\n",
        "                (data[\"EventID\"] < end_event) &\n",
        "                (data[\"Particle\"] == \"gamma\") &\n",
        "                (data[\"r_hit\"] <= detector_radius)\n",
        "            )\n",
        "            df_f = data[mask]\n",
        "\n",
        "            primary = df_f[df_f[\"Type\"] == \"Primary\"]\n",
        "            secondary = df_f[df_f[\"Type\"] == \"Secondary\"]\n",
        "\n",
        "            primary_hist, _ = np.histogram(primary[\"E\"], bins=np.append(E, E[-1] + binwidth))\n",
        "            secondary_hist, _ = np.histogram(secondary[\"E\"], bins=np.append(E, E[-1] + binwidth))\n",
        "\n",
        "            if is_save_point:\n",
        "                combined_primary_hist += primary_hist\n",
        "                combined_secondary_hist += secondary_hist\n",
        "\n",
        "            # Windowing\n",
        "            alpha_window = (E >= peak[\"alpha\"][\"E\"] - peak[\"window\"]) & (E <= peak[\"alpha\"][\"E\"] + peak[\"window\"])\n",
        "            beta_window = (E >= peak[\"beta\"][\"E\"] - peak[\"window\"]) & (E <= peak[\"beta\"][\"E\"] + peak[\"window\"])\n",
        "\n",
        "            alpha_primary_s = primary_hist[alpha_window].sum()\n",
        "            alpha_secondary_s = secondary_hist[alpha_window].sum()\n",
        "            beta_primary_s = primary_hist[beta_window].sum()\n",
        "            beta_secondary_s = secondary_hist[beta_window].sum()\n",
        "\n",
        "            total_secondary_s = alpha_secondary_s + beta_secondary_s\n",
        "            total_primary_s = alpha_primary_s + beta_primary_s\n",
        "\n",
        "            # SNR pro Source\n",
        "            if (alpha_secondary_s + alpha_primary_s) > 0:\n",
        "                SNR[conc_idx][\"alpha_individual\"][s, step - 1] = (\n",
        "                    alpha_secondary_s / np.sqrt(alpha_secondary_s + alpha_primary_s)\n",
        "                )\n",
        "            if (beta_secondary_s + beta_primary_s) > 0:\n",
        "                SNR[conc_idx][\"beta_individual\"][s, step - 1] = (\n",
        "                    beta_secondary_s / np.sqrt(beta_secondary_s + beta_primary_s)\n",
        "                )\n",
        "            if (total_secondary_s + total_primary_s) > 0:\n",
        "                SNR[conc_idx][\"total_individual\"][s, step - 1] = (\n",
        "                    total_secondary_s / np.sqrt(total_secondary_s + total_primary_s)\n",
        "                )\n",
        "\n",
        "            # S0 individual\n",
        "            if s == 0:\n",
        "                signal_over_time_S0[step - 1] += total_secondary_s\n",
        "                background_over_time_S0[step - 1] += total_primary_s\n",
        "\n",
        "            # Summ over all Sources\n",
        "            total_alpha_primary += alpha_primary_s\n",
        "            total_alpha_secondary += alpha_secondary_s\n",
        "            total_beta_primary += beta_primary_s\n",
        "            total_beta_secondary += beta_secondary_s\n",
        "\n",
        "        # Save Histo\n",
        "        if is_save_point:\n",
        "            T_idx = np.where(T_steps == step)[0][0] + 1\n",
        "            field_name = f\"c{conc}_T{T_idx}\"\n",
        "            saved_histograms[field_name] = {\n",
        "                \"primary\": combined_primary_hist,\n",
        "                \"secondary\": combined_secondary_hist,\n",
        "                \"E\": E,\n",
        "                \"time_min\": current_time,\n",
        "            }\n",
        "\n",
        "        total_secondary = total_alpha_secondary + total_beta_secondary\n",
        "        total_primary = total_alpha_primary + total_beta_primary\n",
        "        signal_over_time[step - 1] = total_secondary\n",
        "        background_over_time[step - 1] = total_primary\n",
        "\n",
        "        # combined SNR\n",
        "        if (total_alpha_secondary + total_alpha_primary) > 0:\n",
        "            alpha_combined = total_alpha_secondary / np.sqrt(total_alpha_secondary + total_alpha_primary)\n",
        "        else:\n",
        "            alpha_combined = 0\n",
        "\n",
        "        if (total_beta_secondary + total_beta_primary) > 0:\n",
        "            beta_combined = total_beta_secondary / np.sqrt(total_beta_secondary + total_beta_primary)\n",
        "        else:\n",
        "            beta_combined = 0\n",
        "\n",
        "        if (total_secondary + total_primary) > 0:\n",
        "            total_combined = total_secondary / np.sqrt(total_secondary + total_primary)\n",
        "        else:\n",
        "            total_combined = 0\n",
        "\n",
        "        if step == 1:\n",
        "            SNR[conc_idx][\"alpha_combined\"] = np.zeros(num_steps)\n",
        "            SNR[conc_idx][\"beta_combined\"] = np.zeros(num_steps)\n",
        "            SNR[conc_idx][\"total_combined\"] = np.zeros(num_steps)\n",
        "        SNR[conc_idx][\"alpha_combined\"][step - 1] = alpha_combined\n",
        "        SNR[conc_idx][\"beta_combined\"][step - 1] = beta_combined\n",
        "        SNR[conc_idx][\"total_combined\"][step - 1] = total_combined\n",
        "\n",
        "    SNR[conc_idx][\"signal_over_time\"] = signal_over_time\n",
        "    SNR[conc_idx][\"background_over_time\"] = background_over_time\n",
        "    SNR[conc_idx][\"signal_over_time_S0\"] = signal_over_time_S0\n",
        "    SNR[conc_idx][\"background_over_time_S0\"] = background_over_time_S0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ------------------------------------------------------------\n",
        "# Plot\n",
        "# ------------------------------------------------------------\n",
        "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
        "if len(colors) < 6:\n",
        "    colors = colors * (6 // len(colors) + 1)\n",
        "\n",
        "# ============================================================\n",
        "# FIGURE 1: SNR + LOD\n",
        "# ============================================================\n",
        "fig1, (ax_snr, ax_lod) = plt.subplots(\n",
        "    1, 2,\n",
        "    figsize=(20/2.54, 10/2.54),\n",
        "    constrained_layout=True\n",
        ")\n",
        "\n",
        "# --- SNR ---\n",
        "xLim = (0, 120)\n",
        "yLim = (0, 35)\n",
        "\n",
        "for idx, conc in enumerate(c_vals):\n",
        "    t_data = time_values\n",
        "    snr_data = SNR[idx][\"total_combined\"]\n",
        "\n",
        "    ax_snr.plot(\n",
        "        t_data,\n",
        "        snr_data,\n",
        "        'o',\n",
        "        color=colors[idx],\n",
        "        markersize=4,\n",
        "        markerfacecolor=colors[idx],\n",
        "        label=f\"{conc} ppm\"\n",
        "    )\n",
        "\n",
        "    popt, _ = curve_fit(snr_model, t_data, snr_data, p0=[1.0], maxfev=10000)\n",
        "    A_fitted = popt[0]\n",
        "\n",
        "    t_fit = np.linspace(0, time_values.max(), 1000)\n",
        "    snr_fit = snr_model(t_fit, A_fitted)\n",
        "    ax_snr.plot(\n",
        "        t_fit,\n",
        "        snr_fit,\n",
        "        '-',\n",
        "        color=colors[idx],\n",
        "        label=f\"Fit: {A_fitted:.2f} • √t\"\n",
        "    )\n",
        "\n",
        "for tt in T:\n",
        "    ax_snr.plot([tt, tt], [0, yLim[1]], 'k--')\n",
        "\n",
        "ax_snr.set_title(\"SNR as a function of time with 7x Am241\")\n",
        "ax_snr.set_xlabel(\"Time (min)\")\n",
        "ax_snr.set_ylabel(\"SNR\")\n",
        "ax_snr.set_xlim(xLim)\n",
        "ax_snr.set_ylim(yLim)\n",
        "ax_snr.tick_params(direction='out')\n",
        "ax_snr.legend(loc=\"upper left\")\n",
        "\n",
        "# --- LOD ---\n",
        "xLim_lod = (0, 120)\n",
        "yLim_lod = (0, 1200)\n",
        "\n",
        "# 7x Am241 LOD aus den SNR-Daten\n",
        "A_values = np.zeros(len(c_vals))\n",
        "t_LOD = np.zeros(len(c_vals))\n",
        "sigma_t = np.zeros(len(c_vals))\n",
        "\n",
        "for idx, conc in enumerate(c_vals):\n",
        "    t_data = time_values\n",
        "    snr_data = SNR[idx][\"total_combined\"]\n",
        "    signal_data = SNR[idx][\"signal_over_time\"]\n",
        "    background_data = SNR[idx][\"background_over_time\"]\n",
        "\n",
        "    popt_snr, _ = curve_fit(snr_model, t_data, snr_data, p0=[1.0], maxfev=10000)\n",
        "    A_values[idx] = popt_snr[0]\n",
        "    t_LOD[idx] = 9.0 / (A_values[idx] ** 2)\n",
        "\n",
        "    def lin(x, A):\n",
        "        return A * x\n",
        "\n",
        "    s_fit, _ = curve_fit(lin, t_data, signal_data, p0=[1.0])\n",
        "    b_fit, _ = curve_fit(lin, t_data, background_data, p0=[1.0])\n",
        "\n",
        "    s = s_fit[0]\n",
        "    b = b_fit[0]\n",
        "    t = t_LOD[idx]\n",
        "    sigma_t[idx] = 9 * np.sqrt(((s + 2*b)**2 / s**5) * (1/t) + (b / s**4) * (1/t))\n",
        "\n",
        "ax_lod.errorbar(\n",
        "    t_LOD, c_vals, xerr=sigma_t,\n",
        "    fmt='o', color='r', mfc='r',\n",
        "    label=\"7x Am241\"\n",
        ")\n",
        "\n",
        "popt_lod, _ = curve_fit(lod_model, t_LOD, c_vals, p0=[10, 10])\n",
        "t_fit_lod = np.linspace(t_LOD.min()*0.5, t_LOD.max()*2, 200)\n",
        "c_fit_lod = lod_model(t_fit_lod, *popt_lod)\n",
        "ax_lod.plot(\n",
        "    t_fit_lod, c_fit_lod, 'r-',\n",
        "    label=f\"Fit: A1={popt_lod[0]:.0f}, A2={popt_lod[1]:.0f}\"\n",
        ")\n",
        "\n",
        "# S0-only\n",
        "A_values_S0 = np.zeros(len(c_vals))\n",
        "t_LOD_S0 = np.zeros(len(c_vals))\n",
        "sigma_t_S0 = np.zeros(len(c_vals))\n",
        "\n",
        "for idx, conc in enumerate(c_vals):\n",
        "    t_data = time_values\n",
        "    snr_data_S0 = SNR[idx][\"total_individual\"][0, :]\n",
        "    signal_data_S0 = SNR[idx][\"signal_over_time_S0\"]\n",
        "    background_data_S0 = SNR[idx][\"background_over_time_S0\"]\n",
        "\n",
        "    popt_s0, _ = curve_fit(snr_model, t_data, snr_data_S0, p0=[0.5], maxfev=10000)\n",
        "    A_values_S0[idx] = popt_s0[0]\n",
        "    t_LOD_S0[idx] = 9.0 / (A_values_S0[idx] ** 2)\n",
        "\n",
        "    def lin(x, A):\n",
        "        return A * x\n",
        "\n",
        "    s_fit_S0, _ = curve_fit(lin, t_data, signal_data_S0, p0=[1.0])\n",
        "    b_fit_S0, _ = curve_fit(lin, t_data, background_data_S0, p0=[1.0])\n",
        "\n",
        "    s0 = s_fit_S0[0]\n",
        "    b0 = b_fit_S0[0]\n",
        "    t0 = t_LOD_S0[idx]\n",
        "    sigma_t_S0[idx] = 9 * np.sqrt(((s0 + 2*b0)**2 / s0**5) * (1/t0) + (b0 / s0**4) * (1/t0))\n",
        "\n",
        "ax_lod.errorbar(\n",
        "    t_LOD_S0, c_vals, xerr=sigma_t_S0,\n",
        "    fmt='o', color='b', mfc='b',\n",
        "    label=\"1x Am241\"\n",
        ")\n",
        "\n",
        "popt_lod_S0, _ = curve_fit(lod_model, t_LOD_S0, c_vals, p0=[10, 10])\n",
        "c_fit_lod_S0 = lod_model(t_fit_lod, *popt_lod_S0)\n",
        "ax_lod.plot(\n",
        "    t_fit_lod, c_fit_lod_S0, 'b-',\n",
        "    label=f\"Fit S0: A1={popt_lod_S0[0]:.0f}, A2={popt_lod_S0[1]:.0f}\"\n",
        ")\n",
        "\n",
        "ax_lod.set_xlabel(\"Time (min)\")\n",
        "ax_lod.set_ylabel(\"Concentration (ppm)\")\n",
        "ax_lod.set_xlim(xLim_lod)\n",
        "ax_lod.set_ylim(yLim_lod)\n",
        "ax_lod.set_yticks(np.arange(0, 1201, 100))\n",
        "ax_lod.set_title(\"Limit of detection\")\n",
        "ax_lod.tick_params(direction='out')\n",
        "ax_lod.legend(loc=\"upper right\")\n",
        "\n",
        "fig1.savefig(\"Fig3_topplots.pdf\", transparent=True)\n"
      ],
      "metadata": {
        "id": "dxSPaMvwpiof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================\n",
        "# FIGURE 2: 9 Histogramms\n",
        "# ============================================================\n",
        "fig2, axes = plt.subplots(\n",
        "    3, 3,\n",
        "    figsize=(20/2.54, 20/2.54),\n",
        "    constrained_layout=True\n",
        ")\n",
        "\n",
        "xLim_h = (10, 13)\n",
        "yLim_h = (0, 50)\n",
        "red = (0.7874, 0.0930, 0.1196)\n",
        "blue = (0.0, 0.4470, 0.7410)\n",
        "\n",
        "plot_concs = [500, 200, 100]\n",
        "\n",
        "for row, conc in enumerate(plot_concs):\n",
        "    for col, T_idx in enumerate([1, 2, 3]):\n",
        "        ax = axes[row, col]\n",
        "        key = f\"c{conc}_T{T_idx}\"\n",
        "        hdata = saved_histograms[key]\n",
        "        E_loc = hdata[\"E\"]\n",
        "        prim = hdata[\"primary\"]\n",
        "        sec = hdata[\"secondary\"]\n",
        "        total = prim + sec\n",
        "\n",
        "        ax.fill_between(E_loc, total, step='pre', color=red)\n",
        "        ax.fill_between(E_loc, prim, step='pre', color=blue)\n",
        "\n",
        "        ax.plot([peak[\"alpha\"][\"E\"] - peak[\"window\"]]*2, [0, yLim_h[1]], 'k--',\n",
        "                label=f\"SNR = {SNR[np.where(c_vals==conc)[0][0]]['total_combined'][T_steps[T_idx-1]-1]:.1f}\")\n",
        "        ax.plot([peak[\"alpha\"][\"E\"] + peak[\"window\"]]*2, [0, yLim_h[1]], 'k--')\n",
        "        ax.plot([peak[\"beta\"][\"E\"] - peak[\"window\"]]*2, [0, yLim_h[1]], 'k--')\n",
        "        ax.plot([peak[\"beta\"][\"E\"] + peak[\"window\"]]*2, [0, yLim_h[1]], 'k--')\n",
        "\n",
        "        ax.set_title(f\"{T[T_idx-1]} min - {conc} ppm\", fontsize=8)\n",
        "        ax.set_xlim(xLim_h)\n",
        "        ax.set_ylim(yLim_h)\n",
        "        ax.set_xlabel(\"Energy (keV)\", fontsize=7)\n",
        "        ax.set_ylabel(\"Detected counts\", fontsize=7)\n",
        "        ax.tick_params(direction='out', labelsize=7)\n",
        "\n",
        "        # WICHTIG: nicht quadratisch erzwingen\n",
        "        ax.set_aspect('auto')\n",
        "\n",
        "        ax.legend(loc=\"upper center\", fontsize=6)\n",
        "\n",
        "fig2.savefig(\"Fig3_histograms.pdf\", transparent=True)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# LOD-Werte ausgeben\n",
        "# ------------------------------------------------------------\n",
        "print(\"\\n=== LOD Values with Error Estimates ===\")\n",
        "print(\"7x Am241 Sources:\")\n",
        "print(\"PPM\\tLOD Time (min)\\tSigma_t (min)\")\n",
        "for conc, t_l, s_t in zip(c_vals, t_LOD, sigma_t):\n",
        "    print(f\"{conc}\\t{t_l:.2f}\\t\\t{s_t:.2f}\")\n",
        "\n",
        "print(\"\\n1x Am241 Source:\")\n",
        "print(\"PPM\\tLOD Time (min)\\tSigma_t (min)\")\n",
        "for conc, t_l, s_t in zip(c_vals, t_LOD_S0, sigma_t_S0):\n",
        "    print(f\"{conc}\\t{t_l:.2f}\\t\\t{s_t:.2f}\")\n"
      ],
      "metadata": {
        "id": "d00bqlH5po9a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}